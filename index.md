# ***Recopilacion de tareas*** :)

![](https://puntomedio.mx/wp-content/uploads/2018/06/Ooga-Chaka-Baby.gif)

## Tarea 1
El objetivo de estos ejercicios fue repasar los contenidos vistos durante el semestre anterior y comenzar a utilizar Python como herramienta principal para el resto del curso. Realizamos actividades orientadas a operar con matrices, generar arreglos, repasar el uso de ciclos, crear funciones, así como realizar y editar gráficas, entre otros temas.
  
  [¿Quieres verla?](https://github.com/hector200210/Proyecto-Final/blob/main/Codigos%20py/Tarea_1.ipynb)
  
  ![](https://c.tenor.com/Oi6lRUeRUbAAAAAC/tenor.gif)

## Tarea 2
En esta tarea comenzamos a trabajar con métodos numéricos para encontrar soluciones de ecuaciones no lineales, es decir, sus raíces. Utilizamos métodos como bisección, Newton-Raphson y el método de la secante. La efectividad de cada método depende de la función y de las condiciones iniciales, por lo que algunos pueden funcionar mejor que otros según el caso.

[Ejercicio 1.](https://github.com/hector200210/Proyecto-Final/blob/main/Codigos%20py/Tarea_2_E1.ipynb)

![](https://blog.espol.edu.ec/analisisnumerico/files/2017/09/Biseccion_animado.gif)


[Ejercicio 2.](https://github.com/hector200210/Proyecto-Final/blob/main/Codigos%20py/Tarea_2_E2.ipynb)

![](https://blog.espol.edu.ec/analisisnumerico/files/2017/09/NewtonRaphson_animado.gif) 


[Ejercicio 3.](https://github.com/hector200210/Proyecto-Final/blob/main/Codigos%20py/Tarea_2_E3.ipynb)

![](https://blog.espol.edu.ec/analisisnumerico/files/2017/09/SecanteMetodo_animado.gif)

## Tarea 3
En esta tarea continuamos viendo métodos numéricos para encontrar las raíces de ecuaciones no lineales. En esta ocasión, trabajamos con el método de la falsa posición (o regla falsa) y el método de Birge-Vieta (o Viète). Ambos permiten encontrar soluciones aproximadas a ecuaciones, pero se aplican de manera distinta según el tipo de función.

[Ejercicio 1.](https://github.com/hector200210/Proyecto-Final/blob/main/Codigos%20py/Tarea_3_E1.ipynb)

![](https://blog.espol.edu.ec/analisisnumerico/files/2017/10/posicionfalsa01_GIF.gif)


[Ejercicio 2.](https://github.com/hector200210/Proyecto-Final/blob/main/Codigos%20py/Tarea_3_E2.ipynb)

## Tarea 4
En esta parte de la materia trabajamos con métodos numéricos enfocados en la resolución de sistemas de ecuaciones lineales. Para ello, utilizamos tanto métodos directos como iterativos, dependiendo de las características del sistema a resolver. Entre los métodos abordados se encuentran: Gauss-Jordan, matriz inversa, determinantes, descomposición LU, descomposición de Cholesky, Jacobi y Gauss-Seidel. Cada uno de estos métodos tiene aplicaciones específicas y ventajas particulares en distintos contextos computacionales y matemáticos.

[Ver aqui.](https://github.com/hector200210/Proyecto-Final/blob/main/Codigos%20py/Tarea4.ipynb)

![](https://miro.medium.com/v2/resize:fit:1200/1*dDRXeF51Q_1ixR5Z3PhT2Q.gif)

## Tarea 5
Para este trabajo ya avanzamos de tema, trabajamos con técnicas de derivación e integración numérica, las cuales permiten aproximar soluciones cuando no es posible derivar o integrar una función de forma analítica. Utilizamos métodos como la derivada hacia adelante, hacia atrás y centrada para estimar la pendiente de funciones. En el caso de la integración, aplicamos métodos como el trapecio y Simpson, que nos permiten calcular el área bajo la curva de manera aproximada. Estas herramientas son especialmente útiles cuando se trabaja con datos discretos o funciones complejas que no tienen solución exacta conocida.

[UwU](https://github.com/hector200210/Proyecto-Final/blob/main/Codigos%20py/Tarea5.ipynb)

**Integracion**

![](https://media.giphy.com/media/SqxrZWLVNknUR6L2a3/giphy.gif)


**Derivacion**

![](https://lh3.googleusercontent.com/proxy/5pLmBqxKk4n7De9Zolweg6VnGvoH8y-e0_fMcrneMpsjGJfqN1afa3uicE2tqxXvDU8GZv8u327RIYgLSEynSCQhaw)

## Tarea 6 
Para esta ultima tarea abarcamos técnicas de interpolación numérica y regresión lineal, herramientas fundamentales para el análisis y la estimación de datos. La interpolación numérica nos permite aproximar valores desconocidos dentro del intervalo de un conjunto de datos conocidos. Para ello, se construyen funciones que pasan exactamente por los puntos dados, utilizando métodos como la interpolación lineal, de Newton o de Lagrange.

Por otro lado, la regresión lineal se utiliza para encontrar una relación aproximada entre dos variables, ajustando una recta que representa la tendencia general de los datos. A diferencia de la interpolación, no necesariamente pasa por todos los puntos, ya que su objetivo es minimizar el error y modelar patrones cuando los datos presentan cierta variabilidad o ruido.

Ambas técnicas son muy útiles: la interpolación para estimar valores específicos dentro del rango de datos conocidos, y la regresión para analizar comportamientos o hacer predicciones.

[Ejercicio de interpolacion numerica.](https://github.com/hector200210/Proyecto-Final/blob/main/Codigos%20py/Tarea_6_Interpolado.ipynb)

![](https://blog.espol.edu.ec/analisisnumerico/files/2017/12/DifFinAvanz01_anima.gif)


[Ejercicio de Regresion lineal.](https://github.com/hector200210/Proyecto-Final/blob/main/Codigos%20py/Tarea_6_Regresion.ipynb)

![](https://raw.githubusercontent.com/WillArevalo/Intro-Machine-Learning/master/Apuntes%20Jupyter/regresion-lineal.gif)

# ***Conclusiones***


